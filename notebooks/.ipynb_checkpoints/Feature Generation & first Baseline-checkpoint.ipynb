{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Doc Corpus & chop into TFiDF-BOWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/data_train_test.csv\")\n",
    "df_test, df_train = df[df[\"set\"]==\"test\"], df[df[\"set\"]==\"train\"]\n",
    "train_review = df_train[\"review\"].values\n",
    "train_lbl = df_train[\"sentiment\"].values\n",
    "test_review = df_test[\"review\"].values\n",
    "test_lbl = df_test[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    3.3s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.8s finished\n"
     ]
    }
   ],
   "source": [
    "# NAIVE-BAYES classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None]}]\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=10,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Shit following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To be tested\n",
    "- min/max tfidf\n",
    "- stemming\n",
    "- stopwordremoval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom stemmer/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a custom Porter Stemmer that suits sklearn\n",
    "class PortStem(object):\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.ps.stem(word) for word in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    2.3s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   22.1s finished\n"
     ]
    }
   ],
   "source": [
    "# NAIVE-BAYES classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None, \"english\"]},\n",
    "              {'tfidf__tokenizer': [None, PortStem()]}\n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=2,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   25.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   25.4s finished\n"
     ]
    }
   ],
   "source": [
    "# KNN classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', KNeighborsClassifier()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None]},\n",
    "              {'tfidf__tokenizer': [None, PortStem()]},\n",
    "              {'clf__n_neighbors': [190, 191, 192]},\n",
    "              {'clf__metric': ['cosine']}\n",
    "              \n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=2,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76149999999999995"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  2.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression classification pipeline\n",
    "pl_clf_jobs_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                           ('clf', LogisticRegression()),\n",
    "                          ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning \n",
    "param_grid_lr = [{'tfidf__stop_words' : [None, 'english'],\n",
    "                  'tfidf__tokenizer' : [None, PortStem()],\n",
    "                  'clf__penalty' : [\"l1\", \"l2\"],\n",
    "                  'clf__C' : [1.0, 10.0, 100.0,]\n",
    "                 }]\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs_lr = GridSearchCV(pl_clf_jobs_lr,\n",
    "                              param_grid=param_grid_lr,\n",
    "                              cv=2,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True\n",
    "                              )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs_lr.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85199999999999998"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to go from here?\n",
    "- combine word and genre (\"greatHORROR\")\n",
    "- ngrams (e.g. 2-grams for \"not bad\", etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading tabular IMDB to merge w/ enhanced test-train-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_imdb = pd.read_csv(\"../data/processed/IMDB.csv\", delimiter=\";\")\n",
    "df_test_train_en = pd.read_csv(\"../data/processed/data_train_test_imdb_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting meta information to be considered (from IMDB)\n",
    "- genre\n",
    "- #votings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 23)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "(\"'float' object has no attribute 'split'\", 'occurred at index 283')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-587-f056508acab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_imdb_genres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_imdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"imdbID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"genre\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# concat genres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_imdb_genres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_concatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_imdb_genres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"genre\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-568-b7f087adf818>\u001b[0m in \u001b[0;36mcol_concatter\u001b[0;34m(df, column, delimiter, uppercase)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \"\".join(\n\u001b[1;32m      9\u001b[0m             \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         ),axis=1)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         col_new = df.apply(\n",
      "\u001b[0;32m/Users/joshuagorner/anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4059\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuagorner/anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4155\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4156\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4157\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4158\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-568-b7f087adf818>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \"\".join(\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         ),axis=1)\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: (\"'float' object has no attribute 'split'\", 'occurred at index 283')"
     ]
    }
   ],
   "source": [
    "# retrieve relevant cols\n",
    "df_imdb_genres = df_imdb.loc[:, [\"imdbID\", \"genre\"]]\n",
    "# concat genres\n",
    "df_imdb_genres = col_concatter(df_imdb_genres, column=\"genre\", delimiter=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ï»¿response                                                  True\n",
       "title                                          Northanger Abbey\n",
       "year                                                       1987\n",
       "rated                                                       NaN\n",
       "released                                            15 Feb 1987\n",
       "runtime                                                  88 min\n",
       "genre                                                       NaN\n",
       "director                                           Giles Foster\n",
       "writer                        Jane Austen (novel), Maggie Wadey\n",
       "actors        Katharine Schlesinger, Peter Firth, Robert Har...\n",
       "plot          Catherine Morland is a young woman who enjoys ...\n",
       "language                                                English\n",
       "country                                                 UK, USA\n",
       "awards                                                      NaN\n",
       "poster        http://ia.media-imdb.com/images/M/MV5BMjAzMTQ2...\n",
       "metascore                                                   NaN\n",
       "imdbRating                                                  5,5\n",
       "imdbVotes                                                   712\n",
       "imdbID                                                tt0091649\n",
       "type                                                    episode\n",
       "season                                                        3\n",
       "episode                                                       7\n",
       "seriesID                                              tt0297626\n",
       "Name: 283, dtype: object"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb.iloc[283, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 2)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb_genres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0001032</td>\n",
       "      <td>Short, Drama, Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0004736</td>\n",
       "      <td>Comedy, Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0005077</td>\n",
       "      <td>Short, Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0008458</td>\n",
       "      <td>Drama, Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0012224</td>\n",
       "      <td>Comedy, Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdbID                 genre\n",
       "0  tt0001032  Short, Drama, Horror\n",
       "1  tt0004736         Comedy, Short\n",
       "2  tt0005077         Short, Comedy\n",
       "3  tt0008458        Drama, Romance\n",
       "4  tt0012224         Comedy, Short"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbID</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0001032</td>\n",
       "      <td>DRAMAHORRORSHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0004736</td>\n",
       "      <td>COMEDYSHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0005077</td>\n",
       "      <td>COMEDYSHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0008458</td>\n",
       "      <td>DRAMAROMANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0012224</td>\n",
       "      <td>COMEDYSHORT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdbID             genre\n",
       "0  tt0001032  DRAMAHORRORSHORT\n",
       "1  tt0004736       COMEDYSHORT\n",
       "2  tt0005077       COMEDYSHORT\n",
       "3  tt0008458      DRAMAROMANCE\n",
       "4  tt0012224       COMEDYSHORT"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def col_concatter(df, column, delimiter=\",\", uppercase=True):\n",
    "    \"\"\"Concat multiple values of one column\n",
    "    \"\"\"\n",
    "    df_res = df.copy()\n",
    "    if uppercase:\n",
    "        col_new = df.apply(\n",
    "        lambda row: \"\" if type(row[column]) != str else \\\n",
    "        \"\".join(\n",
    "            sorted(map(lambda x: x.upper(), row[column].split(delimiter)))\n",
    "        ),axis=1)\n",
    "    else:\n",
    "        col_new = df.apply(\n",
    "        lambda row:\n",
    "        \"\".join(\n",
    "            row[column].split(delimiter)\n",
    "        ),axis=1)\n",
    "    df_res[column] = col_new\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review_concatter(df, concat=\"genre\"):\n",
    "    \"\"\"Append the 'concat' to each word of the review\n",
    "    \"\"\"\n",
    "    if not \"review\" in df.columns:\n",
    "        raise ValueError(\"Need to have a 'review' column\")\n",
    "    df_res = df.copy()\n",
    "    rev_new = df.apply(\n",
    "        lambda row:\n",
    "        \" \".join([word+row[concat] for word in row[\"review\"].split()]),\n",
    "        axis=1)\n",
    "    df_res[\"review\"] = rev_new\n",
    "    return df_res"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
