{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Doc Corpus & chop into TFiDF-BOWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/data_train_test.csv\")\n",
    "df_test, df_train = df[df[\"set\"]==\"test\"], df[df[\"set\"]==\"train\"]\n",
    "train_review = df_train[\"review\"].values\n",
    "train_lbl = df_train[\"sentiment\"].values\n",
    "test_review = df_test[\"review\"].values\n",
    "test_lbl = df_test[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    3.3s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.8s finished\n"
     ]
    }
   ],
   "source": [
    "# NAIVE-BAYES classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None]}]\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=10,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Shit following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To be tested\n",
    "- min/max tfidf\n",
    "- stemming\n",
    "- stopwordremoval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom stemmer/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a custom Porter Stemmer that suits sklearn\n",
    "class PortStem(object):\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.ps.stem(word) for word in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    2.3s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   22.1s finished\n"
     ]
    }
   ],
   "source": [
    "# NAIVE-BAYES classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None, \"english\"]},\n",
    "              {'tfidf__tokenizer': [None, PortStem()]}\n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=2,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   25.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   25.4s finished\n"
     ]
    }
   ],
   "source": [
    "# KNN classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', KNeighborsClassifier()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None]},\n",
    "              {'tfidf__tokenizer': [None, PortStem()]},\n",
    "              {'clf__n_neighbors': [190, 191, 192]},\n",
    "              {'clf__metric': ['cosine']}\n",
    "              \n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=2,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76149999999999995"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  2.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression classification pipeline\n",
    "pl_clf_jobs_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                           ('clf', LogisticRegression()),\n",
    "                          ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning \n",
    "param_grid_lr = [{'tfidf__stop_words' : [None, 'english'],\n",
    "                  'tfidf__tokenizer' : [None, PortStem()],\n",
    "                  'clf__penalty' : [\"l1\", \"l2\"],\n",
    "                  'clf__C' : [1.0, 10.0, 100.0,]\n",
    "                 }]\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs_lr = GridSearchCV(pl_clf_jobs_lr,\n",
    "                              param_grid=param_grid_lr,\n",
    "                              cv=2,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True\n",
    "                              )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs_lr.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85199999999999998"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to go from here?\n",
    "- combine genre and word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
