{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Doc Corpus & chop into TFiDF-BOWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/data_train_test.csv\")\n",
    "df_test, df_train = df[df[\"set\"]==\"test\"], df[df[\"set\"]==\"train\"]\n",
    "train_review = df_train[\"review\"].values\n",
    "train_lbl = df_train[\"sentiment\"].values\n",
    "test_review = df_test[\"review\"].values\n",
    "test_lbl = df_test[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    3.3s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.8s finished\n"
     ]
    }
   ],
   "source": [
    "# NAIVE-BAYES classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None]}]\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=10,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Shit following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To be tested\n",
    "- min/max tfidf\n",
    "- stemming\n",
    "- stopwordremoval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom stemmer/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a custom Porter Stemmer that suits sklearn\n",
    "class PortStem(object):\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.ps.stem(word) for word in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    2.3s remaining:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   22.1s finished\n"
     ]
    }
   ],
   "source": [
    "# NAIVE-BAYES classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None, \"english\"]},\n",
    "              {'tfidf__tokenizer': [None, PortStem()]}\n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=2,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   25.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   25.4s finished\n"
     ]
    }
   ],
   "source": [
    "# KNN classification pipeline\n",
    "pl_clf_jobs = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('clf', KNeighborsClassifier()),\n",
    "                       ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning (of preprocessing)\n",
    "param_grid = [{'tfidf__stop_words' : [None]},\n",
    "              {'tfidf__tokenizer': [None, PortStem()]},\n",
    "              {'clf__n_neighbors': [190, 191, 192]},\n",
    "              {'clf__metric': ['cosine']}\n",
    "              \n",
    "             ]\n",
    "\n",
    "\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs = GridSearchCV(pl_clf_jobs,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=2,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=True\n",
    "                          )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76149999999999995"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  2.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression classification pipeline\n",
    "pl_clf_jobs_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                           ('clf', LogisticRegression()),\n",
    "                          ])\n",
    "\n",
    "# Parameter grid for hyper parameter tuning \n",
    "param_grid_lr = [{'tfidf__stop_words' : [None, 'english'],\n",
    "                  'tfidf__tokenizer' : [None, PortStem()],\n",
    "                  'clf__penalty' : [\"l1\", \"l2\"],\n",
    "                  'clf__C' : [1.0, 10.0, 100.0,]\n",
    "                 }]\n",
    "\n",
    "# create grid search\n",
    "gs_clf_jobs_lr = GridSearchCV(pl_clf_jobs_lr,\n",
    "                              param_grid=param_grid_lr,\n",
    "                              cv=2,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=True\n",
    "                              )\n",
    "\n",
    "# run grid search\n",
    "_ = gs_clf_jobs_lr.fit(train_review, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = _.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85199999999999998"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_review, test_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.named_steps[\"clf\"].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to go from here?\n",
    "- combine word and genre (\"greatHORROR\") >> get rid of sklearn pipeline to insert the append at the right position\n",
    "- ngrams (e.g. 2-grams for \"not bad\", etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading tabular IMDB to merge w/ enhanced test-train-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_imdb = pd.read_csv(\"../data/processed/IMDB.csv\", delimiter=\";\")\n",
    "df_test_train_en = pd.read_csv(\"../data/processed/data_train_test_imdb_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting meta information to be considered (from IMDB)\n",
    "- genre\n",
    "- #votings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorgehen\n",
    "1. preprocessing\n",
    "2. stop word removal\n",
    "3. stemming + tokenization\n",
    "4. concatting with (e.g) genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrieve relevant cols\n",
    "df_imdb_genres = df_imdb.loc[:, [\"imdbID\", \"genre\"]]\n",
    "# concat genres\n",
    "df_imdb_genres = col_concatter(df_imdb_genres, column=\"genre\", delimiter=\", \")\n",
    "# rename id col for merging\n",
    "df_imdb_genres.columns = [\"imdb_id\", \"genre\"]\n",
    "# merge that shit\n",
    "df_imdb_merged = pd.merge(df_test_train_en, df_imdb_genres, on=\"imdb_id\")\n",
    "# cleaned reviews\n",
    "df_imdb_merged_pp = port_stemming(\n",
    "    stop_word_removal(stopwords.words(\"english\"), \n",
    "                      df_imdb_merged\n",
    "    )\n",
    ")\n",
    "# combined review and genre\n",
    "df_imdb_merged_pp_concat = review_concatter(df_imdb_merged_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "df_train = \\\n",
    "df_imdb_merged_pp_concat[df_imdb_merged_pp_concat[\"set\"] == \"train\"]\n",
    "df_test = \\\n",
    "df_imdb_merged_pp_concat[df_imdb_merged_pp_concat[\"set\"] == \"test\"]\n",
    "train_review = df_train[\"review\"].values\n",
    "train_lbl = df_train[\"sentiment\"].values\n",
    "test_review = df_test[\"review\"].values\n",
    "test_lbl = df_test[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_train = tfidf.fit_transform(train_review)\n",
    "\n",
    "nb.fit(bow_train, train_lbl)\n",
    "\n",
    "bow_test = tfidf.transform(test_review)\n",
    "nb.score(bow_test, test_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessor(text, lowercase=True):\n",
    "    \"\"\"Remove HTML-tags and digits\n",
    "    \"\"\"\n",
    "    text = re.sub('<[^>]*>', '', text) # get rid of html tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # remove any non char\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenizing(text):\n",
    "    \"\"\"Tokenizing word by word\n",
    "    \"\"\"\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stop_word_removal(sw_list, df, column=\"review\"):\n",
    "    \"\"\"Stopword removal including preprocessing\n",
    "    \"\"\"\n",
    "    if not \"review\" in df.columns:\n",
    "        raise ValueError(\"Need to have a 'review' column\") \n",
    "    df_res = df.copy()  \n",
    "    rev_new = df.apply(\n",
    "        lambda row: \n",
    "        \" \".join([word for word\n",
    "                  in tokenizing(preprocessor(df[column][0]))\n",
    "                  if word not in sw_list]), \n",
    "        axis=1)\n",
    "    df_res[column] = rev_new\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def port_stemming(df, column=\"review\"):\n",
    "    \"\"\"Porter stemming for review column\n",
    "    \"\"\"\n",
    "    if not \"review\" in df.columns:\n",
    "        raise ValueError(\"Need to have a 'review' column\")\n",
    "    ps = PorterStemmer()\n",
    "    df_res = df.copy()\n",
    "    rev_new = df.apply(\n",
    "        lambda row:\n",
    "        \" \".join([ps.stem(word) for word in row[\"review\"].split()]),\n",
    "        axis=1)\n",
    "    df_res[column] = rev_new\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review_concatter(df, concat=\"genre\"):\n",
    "    \"\"\"Append the 'concat' to each word of the review\n",
    "    \"\"\"\n",
    "    if not \"review\" in df.columns:\n",
    "        raise ValueError(\"Need to have a 'review' column\")\n",
    "    df_res = df.copy()\n",
    "    rev_new = df.apply(\n",
    "        lambda row:\n",
    "        \" \".join([word+row[concat] for word in row[\"review\"].split()]),\n",
    "        axis=1)\n",
    "    df_res[\"review\"] = rev_new\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def col_concatter(df, column, delimiter=\",\", uppercase=True):\n",
    "    \"\"\"Concat multiple values of one column\n",
    "    \"\"\"\n",
    "    df_res = df.copy()\n",
    "    if uppercase:\n",
    "        col_new = df.apply(\n",
    "        lambda row: \"\" if type(row[column]) != str else \\\n",
    "        \"\".join(\n",
    "            sorted(map(lambda x: x.upper(), row[column].split(delimiter)))\n",
    "        ),axis=1)\n",
    "    else:\n",
    "        col_new = df.apply(\n",
    "        lambda row:\n",
    "        \"\".join(\n",
    "            row[column].split(delimiter)\n",
    "        ),axis=1)\n",
    "    df_res[column] = col_new\n",
    "    return df_res"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
